{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #for handling csv and csv contents\n",
    "from rdflib import Graph, Literal, RDFS, RDF, URIRef, Namespace, Dataset #basic RDF handling\n",
    "from rdflib.namespace import FOAF , XSD #most common namespaces\n",
    "import urllib.parse #for parsing strings to URI's\n",
    "from iribaker import to_iri\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=urn:x-rdflib:default (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_link = \"http://www.gra.fo/schema/untitled-ekg#\"\n",
    "\n",
    "# name space for resources\n",
    "data = base_link+\"/resource/\"\n",
    "# data = base_link+'/'\n",
    "DATA = Namespace(data)\n",
    "# namespace for vocabulary\n",
    "# vocab = base_link+'/vocab/'\n",
    "vocab = base_link\n",
    "VOCAB = Namespace(vocab)\n",
    "# URI\n",
    "# graph_uri = URIRef(data+'/examplegraph')\n",
    "graph_uri = URIRef(base_link)\n",
    "\n",
    "dataset = Dataset()\n",
    "dataset.bind('g20data', DATA)\n",
    "dataset.bind('g20vocab', VOCAB)\n",
    "\n",
    "## load TBOX\n",
    "g = dataset.graph(graph_uri)\n",
    "dataset.default_context.parse('TBOX_withoutLabels.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading csv for conferences/journals\n",
    "data_folder = \"data/Processed_data/\"\n",
    "df = pd.read_csv(data_folder+\"Conf_Jour_Area.csv\")\n",
    "\n",
    "conf_df = df.loc[df['Type']=='Journal']\n",
    "conf_df = df.loc[df['Type']=='Conference']\n",
    "\n",
    "for _,conf_r in conf_df.iterrows():\n",
    "    # Journal\n",
    "    conf = URIRef(to_iri(data+conf_r[0]))\n",
    "    conf_name = Literal(conf_r[0], datatype=XSD['string'])\n",
    "\n",
    "    g.add((conf, RDFS.label, conf_name))\n",
    "    g.add((conf, RDF.type, VOCAB[\"Conference\"]))\n",
    "\n",
    "    # Journal - related_to -> Area\n",
    "    for area in conf_r[-1].split(\";\"):\n",
    "        area = area.strip()\n",
    "        area = URIRef(to_iri(data+area))\n",
    "        area_name = Literal(area, datatype=XSD['string'])\n",
    "\n",
    "        g.add((area, RDFS.label, area_name))\n",
    "        g.add((conf, VOCAB['journal_related_to'], area))\n",
    "\n",
    "for _,conf_r in conf_df.iterrows():\n",
    "    # Conference\n",
    "    conf = URIRef(to_iri(data+conf_r[0]))\n",
    "    conf_name = Literal(conf_r[0], datatype=XSD['string'])\n",
    "\n",
    "    g.add((conf, RDFS.label, conf_name))\n",
    "    g.add((conf, RDF.type, VOCAB[\"Journal\"]))\n",
    "\n",
    "    # Conference - related_to -> Area\n",
    "    for area in conf_r[-1].split(\";\"):\n",
    "        area = area.strip()\n",
    "        area = URIRef(to_iri(data+area))\n",
    "        area_name = Literal(area, datatype=XSD['string'])\n",
    "\n",
    "        g.add((area, RDFS.label, area_name))\n",
    "        g.add((conf, VOCAB['conference_related_to'], area))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(data_folder+'Redundant_Columns.csv') # another column we need\n",
    "df = pd.read_csv(data_folder+\"Cite_fake_New.csv\")\n",
    "df['Paper Year'] = df1['Year']\n",
    "\n",
    "# putting the same names as in the schema\n",
    "df['Paper Type'] = df['Paper Type'].replace({'Full Paper':'FullPaper', 'Short Paper': 'Shortpaper', 'Demo Paper':'Demopaper'})\n",
    "df['Conference Type'] = df['Conference Type'].replace({\"Regular Conference\":\"Regularconference\", \"Expert Group\": \"Expertgroup\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,row in df.iterrows():\n",
    "    authors = [a.strip() for a in row[1].split(\", \")]\n",
    "    title, source_title, proceeding, volume = row[2:6]\n",
    "    areas = [a.strip() for a in row[6].split(\";\")]\n",
    "    cj_type = row[7]\n",
    "    c_type = row[8]\n",
    "    p_type = row[9]\n",
    "    is_approved = True if row[10] == 'Yes' else False\n",
    "    leader1 = row[11]\n",
    "    leader2 = row[12]\n",
    "    p_year = int(row[13])\n",
    "\n",
    "    paper_n = URIRef(to_iri(data+title))\n",
    "    title_n = Literal(title, datatype=XSD['string'])\n",
    "    g.add((paper_n, RDFS.label, title_n))\n",
    "    year_n = Literal(p_year, datatype=XSD.integer)\n",
    "    g.add((paper_n, VOCAB['paperyear'], year_n))\n",
    "    g.add((paper_n, RDF.type, VOCAB[p_type]))\n",
    "\n",
    "    for author in authors:\n",
    "        author_n = URIRef(to_iri(data+author))\n",
    "        author_name_n = Literal(author, datatype=XSD['string'])\n",
    "        g.add((author_n, RDFS.label, author_name_n))\n",
    "        g.add((author_n, VOCAB['writes'], paper_n))\n",
    "    \n",
    "    for area in areas:\n",
    "        area_n = URIRef(to_iri(data+area))\n",
    "        area_name = Literal(area_n, datatype=XSD['string'])\n",
    "        g.add((area_n, RDFS.label, area_name))\n",
    "        g.add((paper_n, VOCAB['paper_related_to'], area_name))\n",
    "    \n",
    "    if cj_type == 'Conference':\n",
    "        conf_n = URIRef(to_iri(data+source_title))\n",
    "        g.add((paper_n, VOCAB['submitted_to_conference'], conf_n))\n",
    "        g.add((conf_n, RDF.type, VOCAB[c_type]))\n",
    "        \n",
    "        if type(proceeding) != str:\n",
    "            raise(KeyError(\"Proceeding not defined for a conference paper\"))\n",
    "        else:\n",
    "            proceeding_n = URIRef(to_iri(data+proceeding))\n",
    "            proceeding_name_n = Literal(proceeding, datatype=XSD.string)\n",
    "            g.add((proceeding_n, RDFS.label, proceeding_name_n))\n",
    "            g.add((proceeding_n, VOCAB['belongs_to_conference'], conf_n))\n",
    "            if is_approved:\n",
    "                g.add((paper_n, VOCAB['published_in_proceeding'], proceeding_n))\n",
    "        \n",
    "        chair_n = URIRef(to_iri(data+leader1))\n",
    "        chair_name_n = Literal(leader1, datatype=XSD.string)\n",
    "        g.add((chair_n, RDFS.label, chair_name_n))\n",
    "        g.add((conf_n, VOCAB['handled_by_chair'], chair_n))\n",
    "        chair_n = URIRef(to_iri(data+leader2))\n",
    "        chair_name_n = Literal(leader2, datatype=XSD.string)\n",
    "        g.add((chair_n, RDFS.label, chair_name_n))\n",
    "        g.add((conf_n, VOCAB['handled_by_chair'], chair_n))\n",
    "\n",
    "    elif cj_type == 'Journal':\n",
    "        jour_n = URIRef(to_iri(data+source_title))\n",
    "        g.add((paper_n, VOCAB['submitted_to_journal'], jour_n))\n",
    "        \n",
    "        if type(volume) != str:\n",
    "            raise(KeyError(\"Volume not defined for a journal paper\"))\n",
    "        else:\n",
    "            volume_n = URIRef(to_iri(data+volume))\n",
    "            volume_name_n = Literal(volume, datatype=XSD.string)\n",
    "            g.add((volume_n, RDFS.label, volume_name_n))\n",
    "            g.add((volume_n, VOCAB['belongs_to_journal'], jour_n))\n",
    "            if is_approved:\n",
    "                g.add((paper_n, VOCAB['published_in_volume'], volume_n))\n",
    "        \n",
    "        editor_n = URIRef(to_iri(data+leader1))\n",
    "        editor_name_n = Literal(leader1, datatype=XSD.string)\n",
    "        g.add((jour_n, VOCAB['handled_by_editor'], editor_n))\n",
    "        editor_n = URIRef(to_iri(data+leader2))\n",
    "        editor_name_n = Literal(leader2, datatype=XSD.string)\n",
    "        g.add((editor_n, RDFS.label, editor_name_n))\n",
    "        g.add((jour_n, VOCAB['handled_by_editor'], editor_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_folder+\"review_New.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,row in df.iterrows():\n",
    "    title = row[6]\n",
    "    decision = True if row[7]=='1' else False\n",
    "    reviewer = row[9]\n",
    "    review_text = row[10]\n",
    "    assigned_by = row[11]\n",
    "    is_conference = True if row[2] == 'Conference' else False\n",
    "\n",
    "    paper_n = URIRef(to_iri(data+title))\n",
    "\n",
    "    reviewer_n = URIRef(to_iri(data+reviewer))\n",
    "    reviewer_name_n = Literal(title, datatype=XSD['string'])\n",
    "    g.add((reviewer_n, RDFS.label, reviewer_name_n))\n",
    "    \n",
    "    decision_n = URIRef(to_iri(data+f\"decision by {reviewer} for {title}\"))\n",
    "    decision_literal = Literal(f\"decision by {reviewer} for {title}\", datatype=XSD.string)\n",
    "    g.add((decision_n, RDFS.label, decision_literal))\n",
    "    review_text_n = Literal(review_text, datatype=XSD.string)\n",
    "    g.add((decision_n, VOCAB[\"review_text\"], review_text_n))\n",
    "    is_accepted_n = Literal(decision, datatype=XSD.boolean)\n",
    "    g.add((decision_n, VOCAB[\"is_accepted\"], is_accepted_n))\n",
    "\n",
    "    leader_n = URIRef(to_iri(data+assigned_by))\n",
    "\n",
    "    if is_conference:\n",
    "        g.add((leader_n, VOCAB[\"chair_assigns\"], reviewer_n))\n",
    "    else:\n",
    "        g.add((leader_n, VOCAB[\"editor_assigns\"], reviewer_n))\n",
    "    \n",
    "    g.add((reviewer_n, VOCAB[\"submits\"], decision_n))\n",
    "    g.add((decision_n, VOCAB[\"about\"], paper_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=http://www.gra.fo/schema/untitled-ekg# (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.serialize(format='ttl', destination='abox1.ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDM_Lab3_GraphDB-G9u7Mmw6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
